{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For blurring, there are many methods, incuding average blurring, gaussian bluring, and image filtering through 2-D convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method we will be focusing on are 2D convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially convolving an image with a filter.\n",
    "\n",
    "We create a filter of ones by using a numpy matrix of however many pixels our ultimate filter should be (for example, 60 by 60). Then, we take the average value of the entire array by dividing it by the number of pixels (for a 60 x 60, we would divide by 3600). This takes the sum of the color values in the entire matrix for the image, then divides it by the number of pixels in the image to achieve what is commonly referred to as a average blur.\n",
    "\n",
    "For face blurring (live, as we will be implementing), we just take each 'face' we detect, instead of the entire image, and apply the filter to that image by choosing specific x and y values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be viewed in the Blurring iPython Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Noise reduction with a 5x5 Gaussian Filter\n",
    "    * Removing unwanted pixels and random color variations, slightly blurs image\n",
    "    * Variance of noise in the average is smaller than the variance of the pixel noise\n",
    "    * Essentially sets each pixel's value to a weighted average of the surrounding pixels\n",
    "2. Filter the smoothened image with a Sobel Kernel.\n",
    "    * Creates an image which emphasizes edges by giving more weight to the neighbors\n",
    "    * It works by calculating the gradient of image intensity at each pixel within the image. \n",
    "    * It finds the direction of the largest increase from light to dark and the rate of change in that direction.\n",
    "    * Hence, it shows the existence of edges and possible orientations\n",
    "    * ![sobel](https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/sobmasks.gif)\n",
    "        * A kernel works similarly to a filter, and multiplies the image by a certian matrix to achieve a desired effect. One for gx, one for gy. Note that this does not disturb the initial image, but makes a 'copy'\n",
    "        * Then, at each value, the pixel is updated to sqrt(gx^2 + gy^2)\n",
    "3. Find the edge gradient and direction\n",
    "    * Removing all unwanted pixels which do not constitute the edges. This results in thin edges.\n",
    "4. Hysteresis thresholding\n",
    "    * This stage decides which edges are really edges and which are not.\n",
    "    * Checks gradient of those edges to make sure they connect to other edges\n",
    "    * ![](https://docs.opencv.org/3.1.0/hysteresis.jpg)\n",
    "        * Further, it reinforces a threshold. Any edges above its maximum value are called \"sure-edges\"\n",
    "        * Any edges below the maximum value, but are connected to \"sure-edges\", are kept. Other edges below the maximum value are discarded.\n",
    "        * Any edges below the minimum value are automatically discarded.\n",
    "    * Removes small, unwanted pixel noise\n",
    "    * Left with strong edges in the picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This can be viewed in the Edge Detection iPython notebook__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the __Viola Jones__ Algorithm we went over? Well, that extremely powerful algorithm is used by *many* face detection classifiers and programs, including by openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one of the pre-trained classifiers which openCV provides for classification is the Haar-cascade face classifier, along with the Haar-cascade eye classifier, and a couple others which are not relevant to us currently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Viola Jones algorithm, openCV trains a new classifier on images of faces and offers it to us. We simply use it in our code as a classifier, then predict the number of faces in an image by passing the image into the classifier.\n",
    "\n",
    "`\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    " faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned faces matrix contains as many faces as are detected in the image, and then we usually use a for __ in __ loop to do some action with each face, as shown:\n",
    "\n",
    "`\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image_with_detections, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "    `\n",
    "    \n",
    "Where we get the bounding box for each detected face (the region containing the face, as returned by the Viola Jones algorithm), then we do some action with it. In this case, we draw a red bounding box around the face, with a width of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar process is used for eyes. This can be viewed in the FaceDetection iPython notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
