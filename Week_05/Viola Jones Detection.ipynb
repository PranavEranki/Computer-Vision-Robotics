{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viola Jones Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consists of Training and Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is designed to look for frontal faces.\n",
    "\n",
    "Detection algorithm and steps:\n",
    "\n",
    "1. The image is converted to grayscale\n",
    "2. The algorithm gets all faces\n",
    "    - Makes sliding boxes from top left to bottom right, looks for the face\n",
    "    - It looks for this by looking for certain features (eyebrows, eyes, etc)\n",
    "    - If it doesn't detect the proper amount of features per sliding box, it slides to the next one\n",
    "    - Repeats for every box\n",
    "    - Gets all the boxes that contain all the features necessary, saves them\n",
    "3. Gets all faces, then if a lot of them are very close to each other, saves only 1\n",
    "4. Saves the bounding box for the face, displays with the color image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Looking... :\n",
    "![](imgs/JD_1.PNG)\n",
    "\n",
    "2. Looking... close but not enough features:\n",
    "![](imgs/JD_2.PNG)\n",
    "\n",
    "3. Detection of the two 'faces' with proper features:\n",
    "![](imgs/JD_3.PNG)\n",
    "\n",
    "4. Completed search :\n",
    "![](imgs/JD_4.PNG)\n",
    "\n",
    "5. Final face with 1 box on color image:\n",
    "![](imgs/JD_5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar like features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/haar_like_features.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection of some of these haar like features on this face\n",
    "![](imgs/DetectionOfFeatures.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's zoom in on his nose, and identify the values in the nose.\n",
    "![](imgs/ValuesForNose.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the algorithm has identified the feature, it will find how close is that 'nose' to a real life example.\n",
    "1. Takes the average of the normalized values(between 0 and 1) for both sides (0.166, 0.568)\n",
    "2. Then, it subtracts the black from the white averages and gets a value.\n",
    "3. Then, it compares that value (0.402) to a certain threshold(minimum = 0.3) and 'ascertains' in its own system that this feature which it has identified is a nose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That is how the Haar-like features are calculated (assuming there are more than 1). However..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is very, very taxing. To do this faster, there is a 'hack' which uses the __integral image__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the integral image?.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we need to calculate the sum of all the intensities in a specific box. \n",
    "\n",
    "Normally, we would take the average in that box. \n",
    "\n",
    "![](imgs/sampleCalc.PNG)\n",
    "\n",
    "However, this is extremely computationally expensive, especially for even larger features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create the integral image.\n",
    "\n",
    "This is calculated by taking all the values to the top and left of that square.\n",
    "\n",
    "Example:\n",
    "![](imgs/integralImageCalculation.png)\n",
    "\n",
    "Now, for the entire image:\n",
    "\n",
    "![](imgs/completedIntegral.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's cool and all, but what's the point of this?\n",
    "\n",
    "All Haar-like features are rectangles, as noted previously.\n",
    "\n",
    "Instead of calculating all the values in that w x h rectangle, what we could instead do is this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start by taking the integralImage at the bottom right of that rectangle\n",
    "\n",
    "![](imgs/integralUsefulness_1.PNG)\n",
    "\n",
    "2. Then, we will take the value in the integralImage in the top right to substract out and get only the 'bottom' rectangle\n",
    "\n",
    "![](imgs/integralUsefullness_2.PNG)\n",
    "\n",
    "3. Then, we add back the integralImage value for the top left, then subtract the one from the bottom left to get only the square which we are trying to measure.\n",
    "\n",
    "![](imgs/integralUsefullness_3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral image might be very taxing in the beginning, but it is,  in the long run, extremely effective.\n",
    "\n",
    "Regardless of the size of the rectangle, you only have to look at 4 values.\n",
    "\n",
    "For example, if you originally needed 1000 x 1000 values to get the feature, with integral image, you only need 4 values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
