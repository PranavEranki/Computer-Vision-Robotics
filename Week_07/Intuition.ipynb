{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Keypoint Detection\n",
    "\n",
    "The objective of this task is to predict keypoint positions on face images. This can be used as a building block in several applications, such as:\n",
    "\n",
    "    - tracking faces in images and video\n",
    "    - analysing facial expressions\n",
    "    - detecting dysmorphic facial signs for medical diagnosis\n",
    "    - biometrics / face recognition\n",
    "    \n",
    "Detecing facial keypoints is a very challenging problem.  Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: how can we make a facial keypoint detector? Well, at a high level, notice that facial keypoint detection is a convolutional neural network problem. A single face corresponds to a set of 15 facial keypoints (a set of 15 corresponding $(x, y)$ coordinates, i.e., an output point). Because our input data are images, we can employ a convolutional neural network to recognize patterns in our images and learn how to identify these keypoint given sets of labeled data.\n",
    "\n",
    "On a high level, it does this through edge detection, then associating certain patterns of edges with a keypoint. Then, it relays that same information onto new images by detecting edges there and using the relations it has learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we need:\n",
    "- pandas for data\n",
    "- cv2 for the classifier, resizing, and filtering\n",
    "- numpy for its amazing arrays\n",
    "- Pil for pillow processing\n",
    "- and some other helper modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the data, process it, and scale pixel values as necessary to achieve the grayscale effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to come up with a method for plotting the keypoints of each face onto the face itself, so we can view predicted values and also manually examine our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model itself, we will use a 4 layer sequential model from keras, with:\n",
    "- an input layer\n",
    "- two middle layers\n",
    "- one final prediction layer\n",
    "\n",
    "Apart from the model architecture, we will also use the RMSProp optimization algororithm and the mean squared error loss metric, centering our model around accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not go into how the RMS prop algorithm works. For a detailed explanation, go to [this link](http://www.ashukumar27.io/optimization-algorithms/) - warning, it is quite confusing.\n",
    "\n",
    "__On a surface level__, the RMSprop optimization algorithm is similar to a gradient descent algorithm (our classic algorithm) with momentum. It restricts all oscillations in the vertical direction, essentially going from this (blue):\n",
    "![](http://www.ashukumar27.io/assets/neuralnets/decay1.png)\n",
    "\n",
    "to this (green):\n",
    "![](http://www.ashukumar27.io/assets/neuralnets/decay2.png)\n",
    "\n",
    "This way, the data converges to a minumum loss in less epochs, saving both computational power and time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, our program will use the CNN it has constructed, train it on the data given by the Kaggle dataset, and then use that same CNN on the new data to predict the main keypoints of each face.\n",
    "\n",
    "Obviously, we have the drawback that the features originally trained were in grayscale, while the features we will most likely be predicting on will be in color. \n",
    "\n",
    "We can fix this by simply converting the image inputted into a grayscale, predicting the keypoints, and then sending those same points to the color image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
